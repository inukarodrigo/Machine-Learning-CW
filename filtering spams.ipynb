{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4601"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the CSV file\n",
    "df = pd.read_csv('spambase.csv', header=None)\n",
    "# Printing the length of the dataset\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n\n      49   50     51     52     53     54   55    56  57  \n0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n\n[5 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.778</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.756</td>\n      <td>61</td>\n      <td>278</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.01</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 58 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the column labels\n",
    "df.columns = [\n",
    "    'word_freq_make',\n",
    "    'word_freq_address',\n",
    "    'word_freq_all',\n",
    "    'word_freq_3d',\n",
    "    'word_freq_our',\n",
    "    'word_freq_over',\n",
    "    'word_freq_remove',\n",
    "    'word_freq_internet',\n",
    "    'word_freq_order',\n",
    "    'word_freq_mail',\n",
    "    'word_freq_receive',\n",
    "    'word_freq_will',\n",
    "    'word_freq_people',\n",
    "    'word_freq_report',\n",
    "    'word_freq_addresses',\n",
    "    'word_freq_free',\n",
    "    'word_freq_business',\n",
    "    'word_freq_email',\n",
    "    'word_freq_you',\n",
    "    'word_freq_credit',\n",
    "    'word_freq_your',\n",
    "    'word_freq_font',\n",
    "    'word_freq_000',\n",
    "    'word_freq_money',\n",
    "    'word_freq_hp',\n",
    "    'word_freq_hpl',\n",
    "    'word_freq_george',\n",
    "    'word_freq_650',\n",
    "    'word_freq_lab',\n",
    "    'word_freq_labs',\n",
    "    'word_freq_telnet',\n",
    "    'word_freq_857',\n",
    "    'word_freq_data',\n",
    "    'word_freq_415',\n",
    "    'word_freq_85',\n",
    "    'word_freq_technology',\n",
    "    'word_freq_1999',\n",
    "    'word_freq_parts',\n",
    "    'word_freq_pm',\n",
    "    'word_freq_direct',\n",
    "    'word_freq_cs',\n",
    "    'word_freq_meeting',\n",
    "    'word_freq_original',\n",
    "    'word_freq_project',\n",
    "    'word_freq_re',\n",
    "    'word_freq_edu',\n",
    "    'word_freq_table',\n",
    "    'word_freq_conference',\n",
    "    'char_freq_;',\n",
    "    'char_freq_(',\n",
    "    'char_freq_[',\n",
    "    'char_freq_!',\n",
    "    'char_freq_$',\n",
    "    'char_freq_#',\n",
    "    'capital_run_length_average',\n",
    "    'capital_run_length_longest',\n",
    "    'capital_run_length_total',\n",
    "    'spam'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n4006            0.00               0.00           0.00           0.0   \n2313            0.33               0.33           0.00           0.0   \n3691            0.00               0.15           0.00           0.0   \n3853            0.00               0.00           0.10           0.0   \n3176            0.21               0.00           0.42           0.0   \n...              ...                ...            ...           ...   \n4372            1.39               0.00           2.09           0.0   \n2838            0.00               0.00           0.53           0.0   \n4554            0.33               0.00           0.00           0.0   \n703             0.00               0.81           1.47           0.0   \n1032            0.08               0.08           0.76           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n4006           0.00            0.00              0.00                0.00   \n2313           0.00            0.00              0.00                0.00   \n3691           0.15            0.00              0.00                0.00   \n3853           0.00            0.00              0.00                0.10   \n3176           2.54            0.00              0.00                0.00   \n...             ...             ...               ...                 ...   \n4372           0.00            0.00              0.00                0.00   \n2838           0.53            0.00              0.00                0.53   \n4554           0.00            0.00              0.00                0.00   \n703            1.30            0.00              0.98                0.98   \n1032           0.85            1.02              0.25                0.17   \n\n      word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n4006             0.00            0.00  ...        0.000        0.000   \n2313             0.00            0.00  ...        0.306        0.204   \n3691             0.15            0.15  ...        0.019        0.137   \n3853             0.00            0.00  ...        0.074        0.134   \n3176             0.00            0.00  ...        0.028        0.115   \n...               ...             ...  ...          ...          ...   \n4372             0.00            0.00  ...        0.000        0.000   \n2838             0.00            1.07  ...        0.000        0.294   \n4554             0.00            0.00  ...        0.000        0.175   \n703              0.32            1.79  ...        0.000        0.247   \n1032             0.59            0.08  ...        0.000        0.065   \n\n      char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n4006        0.000        0.000        0.000        0.000   \n2313        0.000        0.306        0.000        0.000   \n3691        0.000        0.000        0.000        0.000   \n3853        0.000        0.000        0.059        0.000   \n3176        0.000        0.000        0.000        0.000   \n...           ...          ...          ...          ...   \n4372        0.000        0.254        0.000        0.000   \n2838        0.000        0.367        0.000        0.000   \n4554        0.058        0.116        0.000        0.000   \n703         0.000        0.179        0.674        0.000   \n1032        0.000        0.486        0.118        0.013   \n\n      capital_run_length_average  capital_run_length_longest  \\\n4006                       1.200                           4   \n2313                       5.525                         100   \n3691                       2.276                          20   \n3853                       2.529                          26   \n3176                       2.457                          45   \n...                          ...                         ...   \n4372                       2.000                          13   \n2838                       2.161                          21   \n4554                       1.271                           5   \n703                        2.922                         113   \n1032                       7.561                         669   \n\n      capital_run_length_total  spam  \n4006                        18     0  \n2313                       431     0  \n3691                       485     0  \n3853                       597     0  \n3176                       258     0  \n...                        ...   ...  \n4372                        64     0  \n2838                        67     0  \n4554                        75     0  \n703                        640     1  \n1032                      1414     1  \n\n[100 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4006</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.200</td>\n      <td>4</td>\n      <td>18</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2313</th>\n      <td>0.33</td>\n      <td>0.33</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.306</td>\n      <td>0.204</td>\n      <td>0.000</td>\n      <td>0.306</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>5.525</td>\n      <td>100</td>\n      <td>431</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3691</th>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.15</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.15</td>\n      <td>...</td>\n      <td>0.019</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.276</td>\n      <td>20</td>\n      <td>485</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3853</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.10</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.074</td>\n      <td>0.134</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.059</td>\n      <td>0.000</td>\n      <td>2.529</td>\n      <td>26</td>\n      <td>597</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3176</th>\n      <td>0.21</td>\n      <td>0.00</td>\n      <td>0.42</td>\n      <td>0.0</td>\n      <td>2.54</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.028</td>\n      <td>0.115</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.457</td>\n      <td>45</td>\n      <td>258</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4372</th>\n      <td>1.39</td>\n      <td>0.00</td>\n      <td>2.09</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.254</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.000</td>\n      <td>13</td>\n      <td>64</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2838</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.53</td>\n      <td>0.0</td>\n      <td>0.53</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.53</td>\n      <td>0.00</td>\n      <td>1.07</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.294</td>\n      <td>0.000</td>\n      <td>0.367</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.161</td>\n      <td>21</td>\n      <td>67</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4554</th>\n      <td>0.33</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.175</td>\n      <td>0.058</td>\n      <td>0.116</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.271</td>\n      <td>5</td>\n      <td>75</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>703</th>\n      <td>0.00</td>\n      <td>0.81</td>\n      <td>1.47</td>\n      <td>0.0</td>\n      <td>1.30</td>\n      <td>0.00</td>\n      <td>0.98</td>\n      <td>0.98</td>\n      <td>0.32</td>\n      <td>1.79</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.247</td>\n      <td>0.000</td>\n      <td>0.179</td>\n      <td>0.674</td>\n      <td>0.000</td>\n      <td>2.922</td>\n      <td>113</td>\n      <td>640</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1032</th>\n      <td>0.08</td>\n      <td>0.08</td>\n      <td>0.76</td>\n      <td>0.0</td>\n      <td>0.85</td>\n      <td>1.02</td>\n      <td>0.25</td>\n      <td>0.17</td>\n      <td>0.59</td>\n      <td>0.08</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.065</td>\n      <td>0.000</td>\n      <td>0.486</td>\n      <td>0.118</td>\n      <td>0.013</td>\n      <td>7.561</td>\n      <td>669</td>\n      <td>1414</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 58 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's look at the labelled data\n",
    "df.sample(n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 391\n"
     ]
    }
   ],
   "source": [
    "# Checking if there are duplicate rows in the dataset\n",
    "\n",
    "# get boolean mask of duplicated rows\n",
    "duplicated_rows = df.duplicated()\n",
    "\n",
    "# count the number of duplicated rows\n",
    "num_duplicate_rows = sum(duplicated_rows)\n",
    "\n",
    "print(f\"Number of duplicate rows: {num_duplicate_rows}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Removing duplicate rows\n",
    "df = df.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Setting the spam value to 0 if the \"word_freq_george\" or the \"word_freq_650\" columns are greater than 0.0\n",
    "# Reason: In the documentation(spambase.DOCUMENTATION) it has clearly mentioned it\n",
    "df.loc[(df['word_freq_george'] > 0) | (df['word_freq_650'] > 0), 'spam'] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_george  word_freq_650  spam\n0                  0.0            0.0     1\n1                  0.0            0.0     1\n2                  0.0            0.0     1\n3                  0.0            0.0     1\n4                  0.0            0.0     1\n...                ...            ...   ...\n4596               0.0            0.0     0\n4597               0.0            0.0     0\n4598               0.0            0.0     0\n4599               0.0            0.0     0\n4600               0.0            0.0     0\n\n[4210 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_george</th>\n      <th>word_freq_650</th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4596</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4597</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4598</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4599</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4600</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4210 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at the dataset and check if its updated or not\n",
    "columns_to_display = ['word_freq_george', 'word_freq_650', 'spam']\n",
    "df_subset = df.loc[:, columns_to_display]\n",
    "df_subset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In conclusion, we can state that if the values in the \"word_freq_george\" or \"word_freq_650\" columns are greater than 0.0, then the corresponding values in the \"spam\" column have been updated to 0. This implies that the occurrence of the words \"george\" or \"650\" in an email are strong indicators that the email is not spam."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Save the modified dataframe to a new csv file\n",
    "df.to_csv('modified_dataset.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0            0.00               0.64           0.64           0.0   \n1            0.21               0.28           0.50           0.0   \n2            0.06               0.00           0.71           0.0   \n3            0.00               0.00           0.00           0.0   \n4            0.00               0.00           0.00           0.0   \n\n   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0           0.32            0.00              0.00                0.00   \n1           0.14            0.28              0.21                0.07   \n2           1.23            0.19              0.19                0.12   \n3           0.63            0.00              0.31                0.63   \n4           0.63            0.00              0.31                0.63   \n\n   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n0             0.00            0.00  ...         0.00        0.000   \n1             0.00            0.94  ...         0.00        0.132   \n2             0.64            0.25  ...         0.01        0.143   \n3             0.31            0.63  ...         0.00        0.137   \n4             0.31            0.63  ...         0.00        0.135   \n\n   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0          0.0        0.778        0.000        0.000   \n1          0.0        0.372        0.180        0.048   \n2          0.0        0.276        0.184        0.010   \n3          0.0        0.137        0.000        0.000   \n4          0.0        0.135        0.000        0.000   \n\n   capital_run_length_average  capital_run_length_longest  \\\n0                       3.756                          61   \n1                       5.114                         101   \n2                       9.821                         485   \n3                       3.537                          40   \n4                       3.537                          40   \n\n   capital_run_length_total  spam  \n0                       278     1  \n1                      1028     1  \n2                      2259     1  \n3                       191     1  \n4                       191     1  \n\n[5 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.64</td>\n      <td>0.64</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.778</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.756</td>\n      <td>61</td>\n      <td>278</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>0.28</td>\n      <td>0.50</td>\n      <td>0.0</td>\n      <td>0.14</td>\n      <td>0.28</td>\n      <td>0.21</td>\n      <td>0.07</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.132</td>\n      <td>0.0</td>\n      <td>0.372</td>\n      <td>0.180</td>\n      <td>0.048</td>\n      <td>5.114</td>\n      <td>101</td>\n      <td>1028</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.00</td>\n      <td>0.71</td>\n      <td>0.0</td>\n      <td>1.23</td>\n      <td>0.19</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.64</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.01</td>\n      <td>0.143</td>\n      <td>0.0</td>\n      <td>0.276</td>\n      <td>0.184</td>\n      <td>0.010</td>\n      <td>9.821</td>\n      <td>485</td>\n      <td>2259</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.137</td>\n      <td>0.0</td>\n      <td>0.137</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.63</td>\n      <td>0.00</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>0.31</td>\n      <td>0.63</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.135</td>\n      <td>0.0</td>\n      <td>0.135</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.537</td>\n      <td>40</td>\n      <td>191</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 58 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a reference to the updated dataset\n",
    "df_new = pd.read_csv('modified_dataset.csv', header=0)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into input features and target variable\n",
    "X = df_new.iloc[:, 0:57]\n",
    "y = df_new.iloc[:, 57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.34792164,  1.16102457,  0.67588944, ..., -0.04911671,\n         0.04439849, -0.02130997],\n       [ 0.3521501 ,  0.3684328 ,  0.40439129, ..., -0.00814327,\n         0.24484101,  1.1911417 ],\n       [-0.14790114, -0.24802746,  0.81163851, ...,  0.13387587,\n         2.16908914,  3.18117903],\n       ...,\n       [ 0.65218084, -0.24802746,  0.01653679, ..., -0.12008102,\n        -0.23120996, -0.27996632],\n       [ 2.85240628, -0.24802746, -0.56524496, ..., -0.12783519,\n        -0.23622103, -0.34463041],\n       [-0.34792164, -0.24802746,  0.69528216, ..., -0.12472749,\n        -0.23622103, -0.40606129]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature scaling\n",
    "sc_X = StandardScaler()\n",
    "X_scaled = sc_X.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Reducing the dimensions (no of columns in the dataset) using PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "((4210, 57), (4210, 49))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can insert the no of PCA components we want within the brackets using n_components\n",
    "# This will retain 95% of useful features and then create new dimensions, no of components will get decided by the system\n",
    "pca = PCA(0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X.shape,X_pca.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### In the original dataframe, there are 57 columns, and it got reduced to 49 columns after doing the PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Splitting the data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca,y,random_state=0, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "29.017236257093817"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the value of n_neighbors\n",
    "import math\n",
    "math.sqrt(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always the n_neighbors value has to be an odd number, therefore n_neighbors value is 29\n",
    "n_neighbor = len(y_test) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier(metric='euclidean', n_neighbors=29)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the KNN model\n",
    "# Setting p value into 2, because \"spam\" column has only 2 values, either 0 or 1\n",
    "classifier = KNeighborsClassifier(n_neighbors=29, p=2, metric='euclidean')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n       0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n       1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n       0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n       1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n       0, 1, 1, 0, 0, 0], dtype=int64)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the test set result\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[472,  31],\n       [ 70, 269]], dtype=int64)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model using confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above matrix,\n",
    "The true negative (TN) value is 472, which means that the model correctly identified 472 non-spam emails.\n",
    "The false positive (FP) value is 31, which means that the model incorrectly identified 31 non-spam emails as spam.\n",
    "The true positive (TP) value is 269, which means that the model correctly identified 269 spam emails.\n",
    "The false negative (FN) value is 70, which means that the model incorrectly identified 70 spam emails as non-spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       503\n",
      "           1       0.90      0.79      0.84       339\n",
      "\n",
      "    accuracy                           0.88       842\n",
      "   macro avg       0.88      0.87      0.87       842\n",
      "weighted avg       0.88      0.88      0.88       842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing the experimental results\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier()"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dTree = DecisionTreeClassifier() # Creating an instance\n",
    "dTree.fit(X_train,y_train) # Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n       0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n       1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n       0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n       0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n       0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n       0, 1, 1, 0, 0, 0], dtype=int64)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the test set result\n",
    "predictions = dTree.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[444,  59],\n       [ 51, 288]], dtype=int64)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model using confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above matrix,\n",
    "The true negative (TN) value is 444, which means that the model correctly identified 444 non-spam emails.\n",
    "The false positive (FP) value is 59, which means that the model incorrectly identified 59 non-spam emails as spam.\n",
    "The false negative (FN) value is 51, which means that the model incorrectly identified 51 spam emails as non-spam.\n",
    "The true positive (TP) value is 288, which means that the model correctly identified 288 spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       503\n",
      "           1       0.83      0.85      0.84       339\n",
      "\n",
      "    accuracy                           0.87       842\n",
      "   macro avg       0.86      0.87      0.86       842\n",
      "weighted avg       0.87      0.87      0.87       842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing the experimental results\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison of models\n",
    "Comparing the results of the KNN and Decision Tree models, we can see that both models have similar performance in terms of accuracy, precision, recall, and f1-score. However, the KNN model performs slightly better in terms of recall for class 1 (spam), while the Decision Tree model has slightly higher precision and f1-score for class 1.\n",
    "\n",
    "Overall, the KNN model seems to be slightly better at identifying spam emails, while the Decision Tree model has slightly better precision and f1-score for class 1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
